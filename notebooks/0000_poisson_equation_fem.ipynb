{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Finite Element Method applied to the 1D Poisson Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will solve the **Poisson equation** subject to **Dirichlet boundary conditions**, i.e. we want to find a function $u: \\Omega \\subset \\mathbb{R}^d \\to \\mathbb{R}$, which fulfills\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "        -\\Delta u(x) = f(x) & \\text{if } x \\in \\operatorname{int} \\Omega \\\\\n",
    "        u(x) = g(x)         & \\text{if } x \\in \\partial \\Omega,\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "where $$\\Delta := \\sum_{i = 1}^D \\frac{\\partial}{\\partial x_i}$$ is the **Laplace operator**.\n",
    "For simplicity, we set $\\Omega = [l, r] \\subset \\mathbb{R}$, which means that the problem reduces to\n",
    "\n",
    "$$\n",
    "    \\begin{cases}\n",
    "        -u''(x) = f(x) & \\text{for } x \\in (l, r) \\\\\n",
    "        u(x) = g(x) & \\text{for } x \\in \\{l, r\\}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "We will use the **finite element method** (**FEM**) to solve the problem numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import probnum as pn\n",
    "import scipy.linalg\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "import probnum_galerkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the domain \\Omega = [l, r]\n",
    "domain = (-1.0, 1.0)\n",
    "(l, r) = domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed-form Solution in 1D for $f(x) = c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1D Poisson problem can be solved by simply integrating the PDE and enforcing the boundary conditions afterwards.\n",
    "We have\n",
    "\n",
    "\\begin{align*}\n",
    "    \\int_l^x \\int_l^{\\nu_2} -u''(\\nu_1) \\text{d}\\nu_1 \\text{d}\\nu_2\n",
    "    & = - \\int_l^x (u'(\\nu_2) - u'(l)) \\text{d}\\nu_2 \\\\\n",
    "    & = - (u(x) - u(l)) + u'(l) (x - l) \\\\\n",
    "    & = -u(x) + u(l) + u'(l) (x - l)\n",
    "\\end{align*}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align*}\n",
    "    \\int_l^x \\int_l^{\\nu_2} f(\\nu_1) \\text{d}\\nu_1 \\text{d}\\nu_2\n",
    "    & = c \\int_l^x \\int_l^{\\nu_2} \\text{d}\\nu_1 \\text{d}\\nu_2 \\\\\n",
    "    & = c \\int_l^x (\\nu_2 - l) \\text{d}\\nu_2 \\\\\n",
    "    & = \\frac{c}{2} (x^2 - l^2) - cl(x - l) \\\\\n",
    "    & = \\frac{c}{2} (x - l)(x + l) - cl(x - l).\n",
    "\\end{align*}\n",
    "\n",
    "This means that\n",
    "\n",
    "\\begin{align*}\n",
    "    & -u(x) + u(l) + u'(l) (x - l) = \\frac{c}{2} (x - l)(x + l) - c l(x - l) \\\\\n",
    "    \\Leftrightarrow \\quad\n",
    "    & u(x) = u(l) + \\left( u'(l) + c l - \\frac{c}{2} (x + l) \\right) (x - l).\n",
    "\\end{align*}\n",
    "\n",
    "Obviously $u(l) = g(l)$.\n",
    "However, we still need to find $u'(l)$.\n",
    "This can be done by enforcing the right boundary condition:\n",
    "\n",
    "\\begin{align*}\n",
    "    & g(r) \\stackrel{!}{=} u(r) = g(l) + \\left( u'(l) + c l - \\frac{c}{2} (r + l) \\right) (r - l) \\\\\n",
    "    \\Leftrightarrow \\quad\n",
    "    & u'(l) (r - l) = g(r) - g(l) - c l (r - l) + \\frac{c}{2} (r + l) (r - l) \\\\\n",
    "    \\Leftrightarrow \\quad\n",
    "    & u'(l) = \\frac{g(r) - g(l)}{r - l} - c l + \\frac{c}{2} (r + l),\n",
    "\\end{align*}\n",
    "\n",
    "All in all, we arrive at\n",
    "\n",
    "\\begin{align*}\n",
    "    u(x)\n",
    "    & = g(l) + \\frac{g(r) - g(l)}{r - l} (x - l) + \\frac{c}{2} (r + l - (x + l)) (x - l) \\\\\n",
    "    & = g(l) + \\frac{g(r) - g(l)}{r - l} (x - l) - \\frac{c}{2} (x - r)(x - l).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_1d_solution_constant_rhs(rhs, domain=(0.0, 1.0), boundary_values=(0.0, 0.0)):\n",
    "    (l, r) = domain\n",
    "    (g_l, g_r) = boundary_values\n",
    "    \n",
    "    aff_slope = (g_r - g_l) / (r - l)\n",
    "\n",
    "    def u(x):\n",
    "        return g_l + (aff_slope - (rhs / 2.0) * (x - r)) * (x - l)\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_zero_boundary = poisson_1d_solution_constant_rhs(\n",
    "    rhs=2.0,\n",
    "    domain=domain,\n",
    "    boundary_values=(0.0, 0.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_plot = np.linspace(l, r, 100)\n",
    "\n",
    "plt.plot(xs_plot, u_zero_boundary(xs_plot))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Element Solution for $g(x) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, we will now assume that $g(x) = 0$ for $x \\in \\partial \\Omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Weak Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the finite element method, we must first convert the problem to its so-called **weak formulation**.\n",
    "\n",
    "Let $V$ be a vector space of sufficiently smooth functions $\\Omega \\to \\mathbb{R}$ with $v(x) = 0$ for all $v \\in V$.\n",
    "Note that a function $u \\in V$ solves the problem above if and only if $\\langle -\\Delta u, v \\rangle = \\langle f, v \\rangle$, or equivalently\n",
    "$$-\\int_\\Omega \\Delta u(x) v(x) \\text{d}x = \\int_\\Omega f(x) v(x) \\text{d}x$$\n",
    "for every $v \\in V$.\n",
    "We can introduce additional symmetry to this formulation by applying Green's first identity to the left-hand side of the equation\n",
    "$$-\\int_\\Omega \\Delta u(x) v(x) \\text{d}x = \\int_\\Omega \\nabla u(x) \\cdot \\nabla v(x) \\text{d}x - \\int_{\\partial \\Omega} \\underbrace{v(x)}_{= 0} (\\nabla u(x) \\cdot \\mathbf{n}) \\text{d}S = \\int_\\Omega \\nabla u(x) \\cdot \\nabla v(x) \\text{d}x.$$\n",
    "This means that our original problem can be solved by finding a function $u \\in V$ such that\n",
    "$$\\int_\\Omega \\nabla u(x) \\nabla v(x) \\text{d}x = \\int_\\Omega f(x) v(x) \\text{d}x$$\n",
    "for all $v \\in V$.\n",
    "This is commonly referred to as the weak formulation of the Poisson problem.\n",
    "\n",
    "Note that we did not yet define the function space $V$ precisely.\n",
    "In order to be able to write down the equations above, we require that the first (weak) derivatives of $u$ and $v$ are square integrable.\n",
    "This means that an appropriate choice of $V$ is $V = H_0^1(\\Omega)$, the Sobolev space of functions with square-integrable first (weak) derivatives which attain the value 0 on the boundary of $\\Omega$.\n",
    "\n",
    "In the 1D case, the integral equation simplifies to\n",
    "$$\\int_l^r u'(x) v'(x) \\text{d}x = \\int_l^r f(x) v(x) \\text{d}x.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert the continuous problem above into a discrete problem by replacing $V$ with a finite-dimensional subspace $\\hat{V} \\subset V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The FEM Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the one-dimensional finite element method, typically constucts $\\hat{V}$ as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input domain $\\Omega = [l, r]$ is discretized into a grid $(x_i)_{i = 1}^{n + 2}$ with $l = x_0 \\le x_1 \\le \\dots \\le x_{n + 1} = r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 9\n",
    "grid = np.linspace(l, r, n + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid can then be used to define a set of $n$ basis functions for $\\hat{V}$:\n",
    "$$\n",
    "    \\phi_i(x) :=\n",
    "    \\begin{cases}\n",
    "        \\frac{x - x_{i - 1}}{x_i - x_{i - 1}} & \\text{if } x \\in [x_{i - 1}, x_i] \\\\\n",
    "        \\frac{x_{i + 1} - x}{x_{i + 1} - x_i} & \\text{if } x \\in [x_i, x_{i + 1}] \\\\\n",
    "        0 & \\text{otherwise}\n",
    "    \\end{cases},\n",
    "$$\n",
    "where $i = 1, \\dots, n$.\n",
    "Note that this basis is constructed such that $\\hat{V}$ only contains functions which directly fulfill the boundary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1d_fem_basis_zero_boundary(ax, grid, coords=None, **plot_kwargs):\n",
    "    \"\"\"Assumes an ordered grid\"\"\"\n",
    "    if coords is None:\n",
    "        coords = np.ones_like(grid[1:-1])\n",
    "    \n",
    "    xs = np.vstack((grid[:-2], grid[1:-1], grid[2:]))\n",
    "\n",
    "    ys = np.empty_like(xs)\n",
    "    ys[0, :] = 0.0\n",
    "    ys[1, :] = coords\n",
    "    ys[2, :] = 0.0\n",
    "\n",
    "    ax.plot(xs, ys, **plot_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1d_fem_basis_zero_boundary(plt.gca(), grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Span of the FEM Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function space spanned by this set of basis functions is given by\n",
    "$$\\hat{V} = \\{ f_w := \\sum_{i = 1}^n w_i \\phi_i \\mid w \\in \\mathbb{R}^n \\}.$$\n",
    "\n",
    "To see how $f_w$ behaves, let $x \\in [x_k, x_{k + 1}]$ for $k = 1, \\dots, n - 1$.\n",
    "Then\n",
    "\n",
    "\\begin{align*}\n",
    "    f_w(x)\n",
    "    & = \\sum_{i = 1}^n w_i \\phi_i(x) \\\\\n",
    "    & = \\sum_{i = 1}^n w_i\n",
    "    \\begin{cases}\n",
    "        \\frac{x - x_{i - 1}}{x_i - x_{i - 1}} & \\text{if } x \\in [x_{i - 1}, x_i] \\\\\n",
    "        \\frac{x_{i + 1} - x}{x_{i + 1} - x_i} & \\text{if } x \\in [x_i, x_{i + 1}] \\\\\n",
    "        0 & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "    \\\\\n",
    "    & = w_k \\frac{x_{k + 1} - x}{x_{k + 1} - x_k} + w_{k + 1} \\frac{x - x_{(k + 1) - 1}}{x_{k + 1} - x_{(k + 1) - 1}} \\\\\n",
    "    & = \\frac{x_{k + 1} - x_k + x_k - x}{x_{k + 1} - x_k} w_k + \\frac{x - x_k}{x_{k + 1} - x_k} w_{k + 1} \\\\\n",
    "    & = \\left( 1 - \\frac{x - x_k}{x_{k + 1} - x_k} \\right) w_k + \\frac{x - x_k}{x_{k + 1} - x_k} w_{k + 1}.\n",
    "\\end{align*}\n",
    "\n",
    "We can see that $f_w$ attains value $w_i$ at grid point $i$ and it interpolates linearly in between grid points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fem_zero_boundary_coords_to_fn(grid, coords):\n",
    "    ys_grid = np.empty_like(coords, shape=(grid.shape[0],))\n",
    "    ys_grid[0] = 0.0\n",
    "    ys_grid[1:-1] = coords\n",
    "    ys_grid[-1] = 0.0\n",
    "\n",
    "    return lambda x: np.interp(x, grid, ys_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = u_zero_boundary(grid[1:-1])\n",
    "\n",
    "xs_plot = np.linspace(l, r, 100)\n",
    "\n",
    "plt.plot(xs_plot, fem_zero_boundary_coords_to_fn(grid, w)(xs_plot), label=\"$f_w$\")\n",
    "plot_1d_fem_basis_zero_boundary(plt.gca(), grid, coords=w, alpha=0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Formulation of the Poisson Problem in the FEM basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now express $u$ in the weak formulation by its basis expansion\n",
    "$$u(x) = \\sum_{j = 1}^n \\hat{u}_j \\phi_j(x),$$\n",
    "i.e.\n",
    "$$u'(x) = \\sum_{j = 1}^n \\hat{u}_j \\phi_j'(x).$$\n",
    "This means that we now need to find the coefficients $u_i$ such that\n",
    "$$\\sum_{j = 1}^n \\hat{u}_j \\int_l^r \\phi_j'(x) v'(x) \\text{d}x = \\int_l^r f(x) v(x) \\text{d}x$$\n",
    "for all $v \\in \\hat{V}$.\n",
    "Since the equation is linear in $v$, this is equivalent to solving the system of equations\n",
    "$$\\sum_{j = 1}^n \\hat{u}_j \\int_l^r \\phi_j'(x) \\phi_i'(x) \\text{d}x = \\int_l^r f(x) \\phi_i(x) \\text{d}x,$$\n",
    "where $j = 1, \\dots, n$ for the coeffients $\\hat{u}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we define a matrix $A \\in \\mathbb{R}^{n \\times n}$ with\n",
    "$$A_{ij} := \\int_l^r \\phi_i'(x) \\phi_j'(x) \\text{d}x,$$\n",
    "and a vector $b \\in \\mathbb{R}^n$, where\n",
    "$$b_i := \\int_l^r \\phi_i(x) f(x) \\text{d}x,$$\n",
    "we can equivalently write the weak formulation on $\\hat{V}$ as\n",
    "$$(A \\hat{u})_i = \\sum_{j = 1}^n \\left( \\int_l^r \\phi_i'(x) \\phi_j'(x) \\text{d}x \\right) \\hat{u}_j = \\int_l^r f(x) \\phi_i(x) \\text{d}x = b_i.$$\n",
    "Hence, we have now reduced our original continuous Poisson problem to a linear system $A \\hat{u} = b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Closed-form Expressions for $A$ and $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute closed-form expressions for the entries of $A$.\n",
    "First of all, note that $A$ is symmetric.\n",
    "Moreover, we have\n",
    "$$\n",
    "    \\phi_i'(x) =\n",
    "    \\begin{cases}\n",
    "        \\frac{1}{x_i - x_{i - 1}}, & \\text{if } x \\in [x_i - x_{i - 1}] \\\\\n",
    "        -\\frac{1}{x_{i + 1} - x_i}, & \\text{if } x \\in [x_{i + 1} - x_i] \\\\\n",
    "        0, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "$$\n",
    "(in the weak sense).\n",
    "This implies that $A_{ij} = 0$ for $j \\notin \\{ i - 1, i, i + 1 \\}$, since the support of $\\phi_i'$ only overlaps with the support of $\\phi_j'$ for $j \\in \\{ i - 1, i, i + 1 \\}$.\n",
    "Hence, $A$ is tridiagonal.\n",
    "\n",
    "Consequently, we only need to compute $A_{ii}$ for $i = 1, \\dotsc, n$, and $A_{i,i+1}$ for $i = 1, \\dots, n - 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    A_{ii}\n",
    "    & := \\int_l^r (\\phi_i'(x))^2 \\text{d}x \\\\\n",
    "    & = \\int_{x_{i - 1}}^{x_i} \\left( \\frac{1}{x_i - x_{i - 1}} \\right)^2 \\text{d}x + \\int_{x_i}^{x_{i + 1}} \\left( -\\frac{1}{x_{i + 1} - x_i} \\right)^2 \\text{d}x \\\\\n",
    "    & = \\frac{1}{(x_i - x_{i - 1})^2} \\int_{x_{i - 1}}^{x_i} \\text{d}x + \\frac{1}{(x_{i + 1} - x_i)^2} \\int_{x_i}^{x_{i + 1}} \\text{d}x \\\\\n",
    "    & = \\frac{x_i - x_{i - 1}}{(x_i - x_{i - 1})^2} + \\frac{x_{i + 1} - x_i}{(x_{i + 1} - x_i)^2} \\\\\n",
    "    & = \\frac{1}{x_i - x_{i - 1}} + \\frac{1}{x_{i + 1} - x_i}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    A_{i,i + 1}\n",
    "    & := \\int_l^r \\phi_i'(x) \\phi_{i + 1}'(x) \\text{d}x \\\\\n",
    "    & = \\int_{x_{i - 1}}^{x_i} \\frac{1}{x_i - x_{i - 1}} \\cdot 0 \\text{d}x \\\\\n",
    "    \\qquad & + \\int_{x_i}^{x_{i + 1}} \\left( -\\frac{1}{x_{i + 1} - x_i} \\right) \\left( \\frac{1}{x_{i + 1} - x_i} \\right) \\text{d}x \\\\\n",
    "    \\qquad & + \\int_{x_{i + 1}}^{x_{i + 2}} 0 \\cdot \\left( -\\frac{1}{x_{i + 1} - x_i} \\right) \\text{d}x \\\\\n",
    "    & = -\\frac{1}{(x_{i + 1} - x_i)^2} \\int_{x_i}^{x_{i + 1}} \\text{d}x \\\\\n",
    "    & = -\\frac{x_{i + 1} - x_i}{(x_{i + 1} - x_i)^2} \\\\\n",
    "    & = -\\frac{1}{x_{i + 1} - x_i}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_1d_zero_boundary_operator_fem(grid: np.ndarray) -> pn.linops.Matrix:\n",
    "    # Diagonal\n",
    "    diag = 1 / (grid[1:-1] - grid[:-2])\n",
    "    diag += 1 / (grid[2:] - grid[1:-1])\n",
    "\n",
    "    # Off-Diagonals\n",
    "    offdiag = -1.0 / (grid[2:-1] - grid[1:-2])\n",
    "    \n",
    "    return pn.linops.Matrix(\n",
    "        scipy.sparse.diags(\n",
    "            (offdiag, diag, offdiag),\n",
    "            offsets=(-1, 0, 1),\n",
    "            format=\"csr\",\n",
    "            dtype=np.double,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = poisson_1d_zero_boundary_operator_fem(grid)\n",
    "\n",
    "# Plot a heatmap of the matrix\n",
    "vmax = np.max(np.abs(A.todense()))\n",
    "\n",
    "plt.imshow(A.todense(), cmap=\"bwr\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find a closed-form expression for the right-hand side, we either need to fix a closed-form representation of $f$ or revert to quadrature algorithms.\n",
    "\n",
    "For the sake of simplicity, we will assume $f(x) = c \\in \\mathbb{R}$ in the following.\n",
    "In this case, the entries of $b$ are given by\n",
    "\n",
    "\\begin{align*}\n",
    "    b_i\n",
    "    & = \\int_l^r f(x) \\phi_i(x) \\text{d}x \\\\\n",
    "    & = c \\int_l^r \\phi_i(x) \\text{d}x \\\\\n",
    "    & = c \\left( \\int_{x_{i - 1}}^{x_i} \\frac{x - x_{i - 1}}{x_i - x_{i - 1}} \\text{d}x + \\int_{x_i}^{x_{i + 1}} \\frac{x_{i + 1} - x}{x_{i + 1} - x_i} \\text{d}x \\right) \\\\\n",
    "    & = c \\left( \\frac{1}{x_i - x_{i - 1}} \\int_{x_{i - 1}}^{x_i} x - x_{i - 1} \\text{d}x + \\frac{1}{x_{i + 1} - x_i} \\int_{x_i}^{x_{i + 1}} x_{i + 1} - x \\text{d}x \\right) \\\\\n",
    "    & = c \\left( \\frac{1}{x_i - x_{i - 1}} \\int_0^{x_i - x_{i - 1}} x \\text{d}x + \\frac{1}{x_{i + 1} - x_i} \\int_{x_{i + 1} - x_i}^0 x \\cdot (-1) \\text{d}x \\right) \\\\\n",
    "    & = c \\left( \\frac{1}{x_i - x_{i - 1}} \\left( \\frac{1}{2} x^2 \\bigg \\rvert_0^{x_i - x_{i - 1}} \\right) - \\frac{1}{x_{i + 1} - x_i} \\left( \\frac{1}{2} x^2 \\bigg \\rvert_{x_{i + 1} - x_i}^0 \\right) \\right) \\\\\n",
    "    & = \\frac{c}{2} \\left( \\frac{(x_i - x_{i - 1})^2}{x_i - x_{i - 1}} + \\frac{(x_{i + 1} - x_i)^2}{x_{i + 1} - x_i} \\right) \\\\\n",
    "    & = \\frac{c}{2} (x_i - x_{i - 1} + (x_{i + 1} - x_i)) \\\\\n",
    "    & = \\frac{c}{2} (x_{i + 1} - x_{i - 1}).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_1d_rhs_fem(rhs: float, grid: np.ndarray) -> np.ndarray:\n",
    "    if isinstance(rhs, float):\n",
    "        return (rhs / 2) * (grid[2:] - grid[:-2])\n",
    "    else:\n",
    "        raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = poisson_1d_rhs_fem(c, grid)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Solving the Linear System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step of the finite element method, we need to solve the linear system $A \\hat{u} = b$, where $A$ and $b$ are defined as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = poisson_1d_zero_boundary_operator_fem(grid)\n",
    "b = poisson_1d_rhs_fem(c, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    ncols=3,\n",
    "    figsize=(5, 3.5),\n",
    "    gridspec_kw={\n",
    "        \"width_ratios\": [4, 0.75, .2]\n",
    "    },\n",
    ")\n",
    "\n",
    "vmax = np.max(np.abs(np.hstack([A.todense(), b[:, None]])))\n",
    "\n",
    "img = axes[0].imshow(A.todense(), cmap=\"bwr\", vmin=-vmax, vmax=vmax)\n",
    "axes[1].imshow(b[:, None], cmap=\"bwr\", vmin=-vmax, vmax=vmax)\n",
    "fig.colorbar(img, cax=axes[2])\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system matrix $A$ is sparse which means that we can benefit from a sparse solver like the method of **conjugate gradients**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_zero_boundary_fem_coords, _ = scipy.sparse.linalg.cg(A.A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_zero_boundary_fem = fem_zero_boundary_coords_to_fn(grid, u_zero_boundary_fem_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_plot = np.linspace(l, r, 100)\n",
    "\n",
    "plt.plot(xs_plot, u_zero_boundary(xs_plot), label=\"Exact Solution\")\n",
    "plt.plot(xs_plot, u_zero_boundary_fem(xs_plot), label=\"FEM Solution\")\n",
    "plot_1d_fem_basis_zero_boundary(plt.gca(), grid, coords=u_zero_boundary_fem_coords, alpha=0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Element Solution for Non-zero Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_values = (-1.2, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_poisson_problem_with_boundary_conditions(grid):\n",
    "    (N,) = grid.shape\n",
    "    \n",
    "    diag = np.empty_like(grid)\n",
    "    offdiag = np.empty_like(grid, shape=(N - 1,))\n",
    "\n",
    "    # Laplace Operator on the interior\n",
    "    diag[1:-1] = (  \n",
    "        1 / (grid[1:-1] - grid[:-2])\n",
    "        + 1 / (grid[2:] - grid[1:-1])\n",
    "    )\n",
    "    offdiag[1:-1] = -1.0 / (grid[2:-1] - grid[1:-2])\n",
    "    \n",
    "    # Left boundary condition\n",
    "    diag[0] = 1.0\n",
    "    offdiag[0] = 0.0\n",
    "    \n",
    "    # Right boundary condition\n",
    "    diag[-1] = 1.0\n",
    "    offdiag[-1] = 0.0\n",
    "    \n",
    "    return pn.linops.Matrix(\n",
    "        scipy.sparse.diags(\n",
    "            (offdiag, diag, offdiag),\n",
    "            offsets=(-1, 0, 1),\n",
    "            format=\"csr\",\n",
    "            dtype=grid.dtype,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(discrete_poisson_problem_with_boundary_conditions(grid).todense())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_poisson_problem_with_boundary_conditions_rhs(grid, alpha, boundary_values):\n",
    "    rhs = np.empty_like(grid)\n",
    "    \n",
    "    l, r = boundary_values\n",
    "    \n",
    "    rhs[1:-1] = (alpha / 2) * (grid[2:] - grid[:-2])\n",
    "    \n",
    "    # Left Boundary Condition\n",
    "    rhs[0] = l\n",
    "    rhs[1] += l / (grid[2] - grid[1])\n",
    "    \n",
    "    # Right Boundary Condition\n",
    "    rhs[-1] = r\n",
    "    rhs[-2] += r / (grid[-2] - grid[-3])\n",
    "\n",
    "    return rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_poisson_problem_with_boundary_conditions_rhs(grid, 1.0, boundary_values=boundary_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_poisson_problem_with_boundary_conditions_sol(grid, boundary_values):\n",
    "    A = discrete_poisson_problem_with_boundary_conditions(grid)\n",
    "    b = discrete_poisson_problem_with_boundary_conditions_rhs(grid, 2.0, boundary_values=boundary_values)\n",
    "\n",
    "    (u, _) = scipy.sparse.linalg.cg(A.A, b)\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = discrete_poisson_problem_with_boundary_conditions_sol(grid, boundary_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grid, sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with clean implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "fig, ax = plt.subplots(num=\"Solution to the 1D Poisson Problem\")\n",
    "\n",
    "def interact(domain: tuple, rhs: float, u_l: float, u_r: float, n: int):\n",
    "    domain = tuple(domain)\n",
    "\n",
    "    bvp = probnum_galerkin.problems.PoissonEquation(\n",
    "        domain=domain,\n",
    "        rhs=rhs,\n",
    "        boundary_condition=probnum_galerkin.problems.DirichletBoundaryCondition(\n",
    "            domain,\n",
    "            (u_l, u_r),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Exact Solution\n",
    "    u = bvp.solution\n",
    "    \n",
    "    # FEM Solution\n",
    "    basis = probnum_galerkin.bases.FiniteElementBasis(\n",
    "        domain=domain,\n",
    "        num_elements=n,\n",
    "    )\n",
    "    \n",
    "    solver = probnum_galerkin.solvers.ConjugateGradients()\n",
    "    \n",
    "    linsys = bvp.discretize(basis)\n",
    "    u_fem_coords = solver.solve(linsys)\n",
    "    u_fem = basis.coords2fn(u_fem_coords)\n",
    "    \n",
    "    # Plotting\n",
    "    plot_grid = np.linspace(*domain, 200)\n",
    "    \n",
    "    ax.cla()\n",
    "    ax.plot(plot_grid, u(plot_grid), label=\"Exact Solution\")\n",
    "    ax.plot(plot_grid, u_fem(plot_grid).support, label=\"FEM Solution\")\n",
    "    ax.legend()\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "ipywidgets.interactive(\n",
    "    interact,\n",
    "    domain=ipywidgets.FloatRangeSlider(\n",
    "        value=(-1.0, 1.0),\n",
    "        min=-3.0,\n",
    "        max=3.0,\n",
    "        description=\"Domain\",\n",
    "    ),\n",
    "    rhs=ipywidgets.FloatSlider(\n",
    "        value=2.0,\n",
    "        min=-3.0,\n",
    "        max=3.0,\n",
    "        description=\"f(x)\",\n",
    "    ),\n",
    "    u_l=ipywidgets.FloatSlider(\n",
    "        value=0.0,\n",
    "        min=-2.0,\n",
    "        max=2.0,\n",
    "        description=\"g(l)\",\n",
    "    ),\n",
    "    u_r=ipywidgets.FloatSlider(\n",
    "        value=0.0,\n",
    "        min=-2.0,\n",
    "        max=2.0,\n",
    "        description=\"g(r)\",\n",
    "    ),\n",
    "    n=ipywidgets.IntSlider(\n",
    "        value=1,\n",
    "        min=1,\n",
    "        max=20,\n",
    "        continuous_update=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Numerical Solution of the Linear System\n",
    "\\begin{equation}\n",
    "    \\renewcommand{\\vec}[1]{\\mathbf{#1}}\n",
    "    \\newcommand{\\inprod}[2]{\\left\\langle #1, #2 \\right\\rangle}\n",
    "    \\newcommand{\\norm}[1]{\\left\\lVert #1 \\right\\rVert}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now solve the linear system $A x = b$ using a solution-based probabilistic linear solver.\n",
    "This essentially boils down to online inference in a linear Gaussian model.\n",
    "We assume that we have a prior $$p(x) = \\mathcal{N}(x; \\mu_0, \\Sigma_0)$$ over the solution of the linear system.\n",
    "In each iteration of the solver, we collect information about the solution by projecting onto a one dimensional subspace defined by $s_i$: $$y_i := s_i^T b = (s_i^T A) x.$$\n",
    "Let $S_m := \\begin{pmatrix} s_1, \\dots, s_m \\end{pmatrix}$ and $\\vec{y}_m := \\begin{pmatrix} y_1, \\dots, y_m \\end{pmatrix}^T$.\n",
    "We can now infer $x$ using the Dirac likelihood $$p(y \\mid x) = \\delta(\\vec{y}_m - S_m^T A x).$$\n",
    "Since this is an observation of a linear function of $x$, we can perform inference in closed form.\n",
    "The posterior for step $m$ is then given by $$p(x \\mid y) = \\mathcal{N}(x; \\mu_m, \\Sigma_m),$$ with\n",
    "\\begin{align}\n",
    "    \\mu_m & := \\mu_0 + \\Sigma_0 A^T S_m \\Lambda_m^{-1} S_m^T r_0 \\\\\n",
    "    \\Sigma_m & := \\Sigma_0 - \\Sigma_0 A^T S_m \\Lambda_m^{-1} S_m^T A \\Sigma_0,\n",
    "\\end{align}\n",
    "where $r_0 := b - A \\mu_0$ is the initial residual and $\\Lambda_m := S_m^T A \\Sigma_0 A^T S_m$.\n",
    "\n",
    "To keep inference tractable, we must choose $S_m$ such that $\\Lambda_m$ is diagonal.\n",
    "This can be achieved by considering $A \\Sigma_0 A^T$-orthonormal search directions, i.e. $\\inprod{s_i}{s_j}_{A \\Sigma_0 A^T} = \\delta_{ij}$. In this case, we have $(\\Lambda_m)_{i,j} = \\delta_{ij}$ and thus\n",
    "\\begin{align}\n",
    "    \\mu_m\n",
    "    & = \\mu_0 + \\Sigma_0 A^T S_m S_m^T r_0 \\\\\n",
    "    & = \\mu_0 + \\Sigma_0 A^T \\sum_{i = 1}^m s_i s_i^T r_0 \\\\\n",
    "    & = \\mu_0 + \\Sigma_0 A^T \\sum_{i = 1}^{m - 1} s_i s_i^T r_0 + \\Sigma_0 A^T s_m s_m^T r_0 \\\\\n",
    "    & = \\mu_0 + \\Sigma_0 A^T S_{m - 1} S_{m - 1}^T r_0 + \\Sigma_0 A^T s_m (s_m^T b - s_m^T A \\mu_0) \\\\\n",
    "    & = \\mu_{m - 1} + \\Sigma_0 A^T s_m (s_m^T b - s_m^T A \\mu_0 - \\underbrace{s_m^T A \\Sigma_0 A^T S_{m - 1}}_{= 0} S_{m - 1}^T r_0) \\\\\n",
    "    & = \\mu_{m - 1} + \\Sigma_0 A^T s_m s_m^T (b - A (\\mu_0 + \\Sigma_0 A^T S_{m - 1} S_{m - 1}^T r_0)) \\\\\n",
    "    & = \\mu_{m - 1} + \\Sigma_0 A^T s_m s_m^T \\underbrace{(b - A \\mu_{m - 1})}_{=: r_{m - 1}}\n",
    "\\end{align}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align}\n",
    "    \\Sigma_m\n",
    "    & = \\Sigma_0 - \\Sigma_0 A^T S_m S_m^T A \\Sigma_0 \\\\\n",
    "    & = \\Sigma_0 - \\Sigma_0 A^T \\sum_{i = 1}^m s_i s_i^T A \\Sigma_0 \\\\\n",
    "    & = \\Sigma_0 - \\Sigma_0 A^T \\sum_{i = 1}^{m - 1} s_i s_i^T A \\Sigma_0 - \\Sigma_0 A^T s_i s_i^T A \\Sigma_0 \\\\\n",
    "    & = \\Sigma_0 - \\Sigma_0 A^T S_{m - 1} S_{m - 1}^T A \\Sigma_0 - \\Sigma_0 A^T s_i (\\Sigma_0 A^T s_i)^T \\\\\n",
    "    & = \\Sigma_{m - 1} - \\Sigma_0 A^T s_i (\\Sigma_0 A^T s_i)^T.\n",
    "\\end{align}\n",
    "\n",
    "We can generate $A \\Sigma_0 A^T$-orthonormal search directions $s_m$ on-the-fly as in CG, i.e. $s_m = \\frac{\\tilde{s}_m}{\\norm{\\tilde{s}_m}_{A \\Sigma_0 A^T}}$, $\\tilde{s}_1 = r_0$ and\n",
    "\n",
    "\\begin{align}\n",
    "    \\tilde{s}_m = r_{m - 1} - \\inprod{s_{m - 1}}{r_{m - 1}}_{A \\Sigma_0 A^T} s_{m - 1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Union\n",
    "\n",
    "\n",
    "def problinsolve(\n",
    "    A: pn.linops.LinearOperatorLike,\n",
    "    b: np.ndarray,\n",
    "    prior_x: Optional[Union[pn.randvars.Normal, np.ndarray]] = None,\n",
    "    auto_cov_type: str = \"cg\",\n",
    "    max_num_steps: Optional[int] = None,\n",
    "    rtol: float = 1e-5,\n",
    "    atol: float = 1e-5,\n",
    "    callback: Callable[..., None] = None,\n",
    "):\n",
    "    A = pn.linops.aslinop(A)\n",
    "    \n",
    "    # Prior construction\n",
    "    if isinstance(prior_x, pn.randvars.Normal):\n",
    "        x0 = prior_x.mean.astype(np.result_type(A.dtype, b.dtype), copy=True)\n",
    "        cov0 = prior_x.cov.astype(x0.dtype, copy=True)\n",
    "    else:\n",
    "        if isinstance(prior_x, np.ndarray):\n",
    "            x0 = prior_x.astype(np.result_type(A.dtype, b.dtype), subok=True, copy=True)\n",
    "        else:\n",
    "            assert prior_x is None\n",
    "\n",
    "            x0 = np.zeros(A.shape[1], np.result_type(A.dtype, b.dtype))\n",
    "            \n",
    "        if auto_cov_type == \"id\":\n",
    "            cov0 = np.eye(x0.size, dtype=x0.dtype)\n",
    "        elif auto_cov_type == \"cg\":\n",
    "            cov0 = A.inv()\n",
    "        \n",
    "    # Stopping Criteria\n",
    "    if max_num_steps is None:\n",
    "        max_num_steps = 10 * x0.size\n",
    "        \n",
    "    res_norm_thresh = np.maximum(rtol * np.linalg.norm(b), atol)\n",
    "    \n",
    "    # Callback\n",
    "    if callback is None:\n",
    "        callback = lambda **kwargs: None\n",
    "    \n",
    "    # Initialization\n",
    "    step_idx = 0\n",
    "    \n",
    "    x = x0\n",
    "    cov = cov0\n",
    "    \n",
    "    residual = b - A @ x\n",
    "    residual_norm_sq = np.inner(residual, residual)\n",
    "    residual_norm = np.sqrt(residual_norm_sq)\n",
    "    \n",
    "    stop = (\n",
    "        step_idx >= max_num_steps\n",
    "        or residual_norm < res_norm_thresh\n",
    "    )\n",
    "    \n",
    "    callback(\n",
    "        step_idx=step_idx,\n",
    "        x=pn.randvars.Normal(mean=x.copy(), cov=cov),\n",
    "        residual=residual.copy(),\n",
    "        residual_norm_sq=residual_norm_sq,\n",
    "        residual_norm=residual_norm,\n",
    "        stop=stop,\n",
    "        action=None,\n",
    "        observation=None,\n",
    "        stepdir=None,\n",
    "        stepsize=None,\n",
    "    )\n",
    "    \n",
    "    action = residual\n",
    "    \n",
    "    # Iteration\n",
    "    prev_residual = None\n",
    "    prev_residual_norm_sq = None\n",
    "    \n",
    "    while not stop:\n",
    "        observation = np.inner(action, residual)\n",
    "        \n",
    "        matvec = A @ action\n",
    "        \n",
    "        # Update solution\n",
    "        stepdir = cov @ matvec\n",
    "        \n",
    "        gram = np.inner(matvec, stepdir)\n",
    "        # gram_pinv = 1.0 / gram if gram >= 12 ** -7 else 0.0\n",
    "        gram_pinv = 1.0 / gram\n",
    "        \n",
    "        stepsize = gram_pinv * observation\n",
    "        \n",
    "        x += stepsize * stepdir\n",
    "        cov -= np.outer(stepdir, stepdir) * gram_pinv\n",
    "        \n",
    "        # Update residual\n",
    "        prev_residual = residual\n",
    "        prev_residual_norm_sq = residual_norm_sq\n",
    "\n",
    "        residual = b - A @ x\n",
    "        residual_norm_sq = np.inner(residual, residual)\n",
    "        residual_norm = np.sqrt(residual_norm_sq)\n",
    "        \n",
    "        # Check stopping criteria\n",
    "        step_idx += 1\n",
    "        \n",
    "        stop = (\n",
    "            step_idx >= max_num_steps\n",
    "            or residual_norm < res_norm_thresh\n",
    "        )\n",
    "        \n",
    "        # Callback\n",
    "        callback(\n",
    "            step_idx=step_idx,\n",
    "            x=pn.randvars.Normal(mean=x.copy(), cov=cov),\n",
    "            residual=residual,\n",
    "            residual_norm=residual_norm,\n",
    "            stop=stop,\n",
    "            action=action,\n",
    "            observation=observation,\n",
    "            stepdir=stepdir,\n",
    "            stepsize=stepsize,\n",
    "        )\n",
    "\n",
    "        # Apply stopping criteria\n",
    "        if stop:\n",
    "            break\n",
    "        \n",
    "        # Update action\n",
    "        action = residual + (residual_norm_sq / prev_residual_norm_sq) * action\n",
    "    \n",
    "    return pn.randvars.Normal(\n",
    "        mean=x,\n",
    "        cov=cov,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Union\n",
    "\n",
    "\n",
    "def bayescg(\n",
    "    A: pn.linops.LinearOperatorLike,\n",
    "    b: np.ndarray,\n",
    "    prior_x: Optional[Union[pn.randvars.Normal, np.ndarray]] = None,\n",
    "    auto_cov_type: str = \"cg\",\n",
    "    max_num_steps: Optional[int] = None,\n",
    "    rtol: float = 1e-5,\n",
    "    atol: float = 1e-5,\n",
    "    callback: Callable[..., None] = None,\n",
    "):\n",
    "    A = pn.linops.aslinop(A)\n",
    "    \n",
    "    # Prior construction\n",
    "    if isinstance(prior_x, pn.randvars.Normal):\n",
    "        x0 = prior_x.mean.astype(np.result_type(A.dtype, b.dtype), copy=True)\n",
    "        cov0 = prior_x.cov.astype(x0.dtype, copy=True)\n",
    "    else:\n",
    "        if isinstance(prior_x, np.ndarray):\n",
    "            x0 = prior_x.astype(np.result_type(A.dtype, b.dtype), subok=True, copy=True)\n",
    "        else:\n",
    "            assert prior_x is None\n",
    "\n",
    "            x0 = np.zeros(A.shape[1], np.result_type(A.dtype, b.dtype))\n",
    "            \n",
    "        if auto_cov_type == \"id\":\n",
    "            cov0 = np.eye(x0.size, dtype=x0.dtype)\n",
    "        elif auto_cov_type == \"cg\":\n",
    "            cov0 = A.inv()\n",
    "            \n",
    "    cov0 = pn.linops.aslinop(cov0)\n",
    "        \n",
    "    # Stopping Criteria\n",
    "    if max_num_steps is None:\n",
    "        max_num_steps = 10 * x0.size\n",
    "        \n",
    "    res_norm_thresh = np.maximum(rtol * np.linalg.norm(b), atol)\n",
    "    \n",
    "    # Callback\n",
    "    if callback is None:\n",
    "        callback = lambda **kwargs: None\n",
    "    \n",
    "    # Initialization\n",
    "    step_idx = 0\n",
    "    \n",
    "    x = x0\n",
    "    cov = cov0\n",
    "    \n",
    "    nu = 0.0\n",
    "    cov_scale = 0.0\n",
    "    \n",
    "    residual = b - A @ x\n",
    "    residual_norm_sq = np.inner(residual, residual)\n",
    "    residual_norm = np.sqrt(residual_norm_sq)\n",
    "    \n",
    "    stop = (\n",
    "        step_idx >= max_num_steps\n",
    "        or residual_norm < res_norm_thresh\n",
    "    )\n",
    "    \n",
    "    callback(\n",
    "        step_idx=step_idx,\n",
    "        x=pn.randvars.Normal(mean=x0.copy(), cov=cov0),\n",
    "        residual=residual.copy(),\n",
    "        residual_norm_sq=residual_norm_sq,\n",
    "        residual_norm=residual_norm,\n",
    "        stop=stop,\n",
    "        action=None,\n",
    "        stepdir=None,\n",
    "        stepsize=None,\n",
    "    )\n",
    "    \n",
    "    # Iteration\n",
    "    action = residual\n",
    "    matvec = A @ action\n",
    "    \n",
    "    prev_residual = None\n",
    "    prev_residual_norm_sq = None\n",
    "    \n",
    "    prev_actions = []\n",
    "    prev_matvecs = []\n",
    "    \n",
    "    while not stop:\n",
    "        # Update solution\n",
    "        stepdir = cov0 @ matvec  # Sigma0 @ A @ s\n",
    "        \n",
    "        gram = np.inner(matvec, stepdir)  # s @ A @ Sigma0 @ A @ s\n",
    "        gram_pinv = 1.0 / gram if gram >= 10 ** -5 else 0.0\n",
    "        # gram_pinv = 1.0 / gram\n",
    "        \n",
    "        stepsize = gram_pinv * residual_norm_sq  # \n",
    "        \n",
    "        x += stepsize * stepdir\n",
    "        cov -= np.outer(stepdir, stepdir) * gram_pinv\n",
    "        \n",
    "        step_idx += 1\n",
    "        \n",
    "        nu += residual_norm_sq * gram_pinv\n",
    "        cov_scale = nu / step_idx\n",
    "        \n",
    "        # Update residual\n",
    "        prev_residual = residual\n",
    "        prev_residual_norm_sq = residual_norm_sq\n",
    "\n",
    "        residual = b - A @ x\n",
    "        residual_norm_sq = np.inner(residual, residual)\n",
    "        residual_norm = np.sqrt(residual_norm_sq)\n",
    "        \n",
    "        # Check stopping criteria\n",
    "        stop = (\n",
    "            step_idx >= max_num_steps\n",
    "            or residual_norm < res_norm_thresh\n",
    "        )\n",
    "        \n",
    "        # Callback\n",
    "        callback(\n",
    "            step_idx=step_idx,\n",
    "            x=pn.randvars.Normal(mean=x.copy(), cov=cov_scale * cov),\n",
    "            # x=pn.randvars.Normal(mean=x.copy(), cov=cov),\n",
    "            cov_scale=cov_scale,\n",
    "            residual=residual,\n",
    "            residual_norm=residual_norm,\n",
    "            stop=stop,\n",
    "            action=action,\n",
    "            stepdir=stepdir,\n",
    "            stepsize=stepsize,\n",
    "        )\n",
    "\n",
    "        # Apply stopping criteria\n",
    "        if stop:\n",
    "            break\n",
    "        \n",
    "        # Update action\n",
    "        prev_actions.append(action)\n",
    "        prev_matvecs.append(matvec)\n",
    "        \n",
    "        action = residual + (residual_norm_sq / prev_residual_norm_sq) * action\n",
    "        matvec = A @ action\n",
    "        \n",
    "        # Reorthogonalize\n",
    "        for prev_action, prev_matvec in zip(prev_actions, prev_matvecs):\n",
    "            action -= (np.inner(prev_matvec, cov0 @ matvec) / np.inner(prev_matvec, cov0 @ prev_matvec)) * prev_action\n",
    "    \n",
    "    return pn.randvars.Normal(\n",
    "        mean=x,\n",
    "        cov=cov_scale * cov,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.random.randn(10, 10)\n",
    "A = M @ M.T + np.eye(10)\n",
    "b = np.random.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = bayescg(A, b)\n",
    "sol.mean, sol.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_1d_laplace_solve_bayescg(grid: np.ndarray, **bayescg_kwargs) -> pn.randvars.Normal:\n",
    "    A = discrete_1d_laplace_operator(grid)\n",
    "    b = discrete_1d_laplace_rhs(grid, 2.0)\n",
    "\n",
    "    u_no_boundary = bayescg(A, -b, **bayescg_kwargs)\n",
    "    \n",
    "    u_mean = np.empty_like(u_no_boundary.mean, shape=(u_no_boundary.size + 2,))\n",
    "    u_mean[0] = 0.0\n",
    "    u_mean[1:-1] = u_no_boundary.mean\n",
    "    u_mean[-1] = 0.0\n",
    "    \n",
    "    u_cov = np.empty_like(u_no_boundary.mean, shape=(u_no_boundary.size + 2, u_no_boundary.size + 2))\n",
    "    u_cov[0, :] = 0\n",
    "    u_cov[-1, :] = 0\n",
    "    u_cov[:, 0] = 0\n",
    "    u_cov[:, -1] = 0\n",
    "    u_cov[1:-1, 1:-1] = u_no_boundary.cov.todense()\n",
    "    \n",
    "    return pn.randvars.Normal(u_mean, u_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = discrete_1d_laplace_solve_bayescg(grid, max_num_steps=10, rtol=0, atol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grid, u.mean)\n",
    "plt.fill_between(grid, u.mean - 2 * u.var, u.mean + 2 * u.var, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "def animate_bayescg_poisson_fem(**bayescg_kwargs):\n",
    "    N = grid.size\n",
    "    \n",
    "    # Run the algorithm and log step statistics\n",
    "    step_stats = []\n",
    "    step_residual_norms = []\n",
    "    step_cov_traces = []\n",
    "\n",
    "    def _callback(x: pn.randvars.Normal, residual_norm: np.ndarray, **kwargs):\n",
    "        u_mean = np.empty_like(x.mean, shape=(x.size + 2,))\n",
    "        u_mean[0] = 0.0\n",
    "        u_mean[1:-1] = x.mean.copy()\n",
    "        u_mean[-1] = 0.0\n",
    "\n",
    "        u_std = np.empty_like(x.mean, shape=(x.size + 2,))\n",
    "        u_std[0] = 0.0\n",
    "        u_std[1:-1] = np.sqrt(np.maximum(x.var, 0.0))\n",
    "        u_std[-1] = 0.0\n",
    "\n",
    "        step_stats.append((u_mean, u_std))\n",
    "        step_residual_norms.append(residual_norm)\n",
    "        step_cov_traces.append(np.mean(x.var))\n",
    "\n",
    "    discrete_1d_laplace_solve_bayescg(\n",
    "        grid,\n",
    "        max_num_steps=N - 2,\n",
    "        callback=_callback,\n",
    "        **bayescg_kwargs\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(15, 6))\n",
    "    plt.close()\n",
    "\n",
    "    def animate(step_idx):\n",
    "        ax[0].cla()\n",
    "        ax[1].cla()\n",
    "\n",
    "        mean, std = step_stats[step_idx]\n",
    "\n",
    "        fig.suptitle(f\"1D Poisson - FEM (N = {N}) - BayesCG - Iteration {step_idx:03d}\")\n",
    "\n",
    "        ax[0].set_title(\"Solution\")\n",
    "        ax[0].set_ylim(-1.3, np.max(mean + 2 * std) + 0.1)\n",
    "        ax[0].plot(grid, mean)\n",
    "        ax[0].fill_between(grid, mean - 2 * std, mean + 2 * std, alpha=0.2)\n",
    "\n",
    "        ax[1].set_title(\"Stopping Criteria\")\n",
    "        ax[1].plot(step_residual_norms[:step_idx + 1], \"C0\", label=\"residual norm\")\n",
    "        # ax[1].plot(step_cov_traces[:step_idx + 1], \"C0\", label=\"cov trace\")\n",
    "        ax[1].legend(loc=\"upper right\")\n",
    "        ax[1].set_xlabel(\"Iterations\")\n",
    "\n",
    "    return animation.FuncAnimation(\n",
    "        fig,\n",
    "        func=animate,\n",
    "        frames=len(step_stats),\n",
    "        interval=200,\n",
    "        repeat_delay=4000,\n",
    "        blit=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "anim = animate_bayescg_poisson_fem()\n",
    "\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save(\"../results/fem_probsolve.gif\", animation.PillowWriter(fps=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_1d_fourier_solve_bayescg(N: int, domain=(-1.0, 1.0), **bayescg_kwargs):\n",
    "    A = discrete_1d_fourier_laplace(N, domain)\n",
    "    b = discrete_1d_fourier_rhs(2.0, N, domain)\n",
    "    \n",
    "    return bayescg(-A, b, **bayescg_kwargs)\n",
    "\n",
    "def coeffs_to_prob_solution(coeffs: pn.randvars.Normal, domain=(-1.0, 1.0)):\n",
    "    ns = np.arange(1, coeffs.size + 1)\n",
    "\n",
    "    def _sol(grid):\n",
    "        basis = fourier_basis_element_1d(  # shape: (G, N)\n",
    "            grid[:, None],\n",
    "            ns[None, :],\n",
    "            domain,\n",
    "        )\n",
    "        \n",
    "        return basis @ coeffs\n",
    "    \n",
    "    return _sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = discrete_1d_fourier_solve_bayescg(10)\n",
    "sol = coeffs_to_prob_solution(coeffs)\n",
    "\n",
    "coeffs.mean, coeffs.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_grid = sol(grid)\n",
    "\n",
    "plt.plot(grid, sol_grid.mean, color=\"C1\")\n",
    "plt.fill_between(grid, sol_grid.mean - 2 * sol_grid.var, sol_grid.mean + 2 * sol_grid.var, color=\"C0\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditioning the Prior on Observations of the Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have (noisy) measurements of the solution of the PDE, we can use the information to speed up inference.\n",
    "\n",
    "Let $(v_i)_{i = 1}^n$ be the chosen basis.\n",
    "In our formulation, we posit a multivariate Gaussian prior over the coefficients $\\vec{a} \\in \\mathbb{R}^n$ of the discretized solution $\\hat{u} = \\sum_{i = 1}^n a_i v_i$ to the PDE, i.e. $\\vec{a} \\sim \\mathcal{N}(\\mu_0, \\Sigma_0)$.\n",
    "We can relate the discretized solution $\\hat{u}$ to the coefficients by a linear operator $$(\\mathcal{L}_u \\vec{a})(x) = \\sum_{i = 1}^n a_i v_i(x).$$\n",
    "Moreover, the solution can be evaluated at several locations $x_1, \\dotsc, x_m \\in \\Omega$ by another linear operator $$(\\mathcal{L}_\\delta u)_j = \\int_\\Omega \\delta(\\chi - x_j) u(\\chi) d \\chi = u(x_j).$$\n",
    "All in all, we obtain the following linear operator which maps $\\vec{a}$ to a vector of measurements at $x_1, \\dotsc, x_m \\in \\Omega$: $$(L_y \\vec{a})_j = (\\mathcal{L}_\\delta \\mathcal{L}_u \\vec{a})_j = \\int_\\Omega \\delta(\\chi - x_j) (\\mathcal{L}_u \\vec{a})(\\chi) d \\chi = \\sum_{i = 1}^n a_i \\int_\\Omega \\delta(\\chi - x_j) v_i(\\chi) d\\chi = \\sum_{i = 1}^n a_i v_i(x_j)$$\n",
    "If we now assume additive Gaussian measurement noise on independent observations $y_1, \\dotsc, y_m$ of the solution at locations $x_1, \\dotsc, x_m \\in \\Omega$, we obtain the following measurement likelihood:\n",
    "$$p(y_1, \\dots, y_m \\mid u(x_1), \\dotsc, u(x_m)) = \\mathcal{N}(\\vec{y} \\mid \\begin{pmatrix} u(x_1), \\dotsc, u(x_m) \\end{pmatrix}^T, \\Lambda),$$\n",
    "or, equivalently,\n",
    "$$p(y_1, \\dots, y_m \\mid \\vec{a}) = \\mathcal{N}(\\vec{y} \\mid L_\\vec{y} \\vec{a}, \\Lambda).$$\n",
    "Since the model is linear-Gaussian, we can compute the posterior in closed form.\n",
    "Note that this is exactly the supervised regression setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 103\n",
    "\n",
    "grid = np.linspace(-1, 1, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytic solution to the 1-d Poisson problem with constant 2.0 as rhs\n",
    "ana_sol = lambda xs: xs ** 2 - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the solution at a grid point\n",
    "meas_idcs = np.array([N // 4, N // 2, 3 * N // 4])\n",
    "\n",
    "N_meas = meas_idcs.size\n",
    "\n",
    "meas_xs = grid[meas_idcs]\n",
    "true_ys = ana_sol(meas_xs)\n",
    "\n",
    "# Add measurement noise\n",
    "measurement_noise = pn.randvars.Normal(\n",
    "    mean=np.zeros(N_meas, dtype=np.double),\n",
    "    cov=pn.linops.Scaling((1e-2) ** 2, shape=N_meas, dtype=np.double),\n",
    ")\n",
    "\n",
    "meas_ys = true_ys + measurement_noise.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_ys - true_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the problem\n",
    "A = discrete_1d_laplace_operator(grid)\n",
    "b = discrete_1d_laplace_rhs(grid, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the prior\n",
    "prior = pn.randvars.Normal(\n",
    "    mean=np.zeros(N - 2, dtype=np.double),\n",
    "    cov=A.inv(),\n",
    ")\n",
    "\n",
    "np.linalg.cond(prior.dense_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the observation operator\n",
    "entries = np.ones(N_meas, dtype=np.double)\n",
    "row_idcs = np.arange(N_meas)\n",
    "col_idcs = meas_idcs - 1  # the solution vector always excludes the boundary elements, so indices must be shifted by 1\n",
    "\n",
    "L_yu = scipy.sparse.coo_matrix(\n",
    "    (entries, (row_idcs, col_idcs)),\n",
    "    shape=(N_meas, N - 2),\n",
    ").tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the noise model\n",
    "noise_model = pn.randvars.Normal(\n",
    "    mean=np.zeros(N_meas, dtype=np.double),\n",
    "    cov=measurement_noise.cov,\n",
    "    # cov=10 * measurement_noise.cov,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def posterior_linear_gaussian_model(\n",
    "    prior: pn.randvars.Normal,\n",
    "    A: Union[np.ndarray, pn.linops.LinearOperatorLike],\n",
    "    measurement_noise: pn.randvars.Normal,\n",
    "    measurements: np.ndarray,\n",
    ") -> pn.randvars.Normal:\n",
    "    prior_x = prior\n",
    "    \n",
    "    if not isinstance(A, np.ndarray):\n",
    "        A = pn.linops.aslinop(A)\n",
    "    \n",
    "    prior_pred_cov_yx = A @ prior_x.cov\n",
    "    \n",
    "    prior_pred_Ax = pn.randvars.Normal(\n",
    "        mean=A @ prior.mean,\n",
    "        cov=prior_pred_cov_yx @ A.T,\n",
    "    )\n",
    "    prior_pred_y = prior_pred_Ax + measurement_noise\n",
    "    \n",
    "    gain = scipy.linalg.cho_solve(\n",
    "        scipy.linalg.cho_factor(prior_pred_y.dense_cov),\n",
    "        prior_pred_cov_yx if isinstance(prior_pred_cov_yx, np.ndarray) else prior_pred_cov_yx.todense()\n",
    "    ).T\n",
    "    \n",
    "    return pn.randvars.Normal(\n",
    "        mean=prior.mean + gain @ (measurements - prior_pred_y.mean),\n",
    "        cov=prior.cov - gain @ prior_pred_cov_yx\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition the prior on the measurements\n",
    "prior_cond_meas = posterior_linear_gaussian_model(\n",
    "    prior=prior,\n",
    "    A=L_yu,\n",
    "    measurement_noise=noise_model,\n",
    "    measurements=meas_ys,\n",
    ")\n",
    "\n",
    "np.linalg.cond(prior_cond_meas.dense_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grid[1:-1], prior_cond_meas.mean)\n",
    "plt.fill_between(grid[1:-1], prior_cond_meas.mean - 2 * prior_cond_meas.std, prior_cond_meas.mean + 2 * prior_cond_meas.std, alpha=0.1)\n",
    "plt.scatter(meas_xs, meas_ys, marker=\"+\")\n",
    "# plt.errorbar(meas_xs, meas_ys, yerr=2 * measurement_noise.std, marker=\"+\", linestyle=\"\", capsize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "anim = animate_bayescg_poisson_fem(prior_x=prior_cond_meas, atol=0, rtol=0)\n",
    "\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save(\"../results/fem_probsolve_data.gif\", animation.PillowWriter(fps=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(np.sort(A.eigvals()))\n",
    "plt.semilogy(np.sort((A @ prior_cond_meas.cov @ A).eigvals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = np.sort((A @ prior_cond_meas.cov @ A).eigvals())\n",
    "spec.min(), spec.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = np.sort(A.eigvals())\n",
    "spec.min(), spec.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:probnum]",
   "language": "python",
   "name": "conda-env-probnum-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
