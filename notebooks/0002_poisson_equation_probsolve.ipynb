{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3245ab9b-7883-4107-996e-50237da27043",
   "metadata": {},
   "source": [
    "# Probabilistic Numerical Solution of the Linear System\n",
    "\\begin{equation}\n",
    "    \\renewcommand{\\vec}[1]{\\mathbf{#1}}\n",
    "    \\newcommand{\\inprod}[2]{\\left\\langle #1, #2 \\right\\rangle}\n",
    "    \\newcommand{\\norm}[1]{\\left\\lVert #1 \\right\\rVert}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74866186-99ae-4c0f-a239-3507bf6283cd",
   "metadata": {},
   "source": [
    "We now solve the linear system $A x = b$ using a solution-based probabilistic linear solver.\n",
    "This essentially boils down to online inference in a linear Gaussian model.\n",
    "We assume that we have a prior $$p(x) = \\mathcal{N}(x; \\mu_0, \\Sigma_0)$$ over the solution of the linear system.\n",
    "In each iteration of the solver, we collect information about the solution by projecting onto a one dimensional subspace defined by $s_i$: $$y_i := s_i^T b = (s_i^T A) x.$$\n",
    "Let $S_m := \\begin{pmatrix} s_1, \\dots, s_m \\end{pmatrix}$ and $\\vec{y}_m := \\begin{pmatrix} y_1, \\dots, y_m \\end{pmatrix}^T$.\n",
    "We can now infer $x$ using the Dirac likelihood $$p(y \\mid x) = \\delta(\\vec{y}_m - S_m^T A x).$$\n",
    "Since this is an observation of a linear function of $x$, we can perform inference in closed form.\n",
    "The posterior for step $m$ is then given by $$p(x \\mid y) = \\mathcal{N}(x; \\mu_m, \\Sigma_m),$$ with\n",
    "\\begin{align}\n",
    "    \\mu_m & := \\mu_0 + \\Sigma_0 A^T S_m \\Lambda_m^{-1} S_m^T r_0 \\\\\n",
    "    \\Sigma_m & := \\Sigma_0 - \\Sigma_0 A^T S_m \\Lambda_m^{-1} S_m^T A \\Sigma_0,\n",
    "\\end{align}\n",
    "where $r_0 := b - A \\mu_0$ is the initial residual and $\\Lambda_m := S_m^T A \\Sigma_0 A^T S_m$.\n",
    "\n",
    "To keep inference tractable, we must choose $S_m$ such that $\\Lambda_m$ is diagonal.\n",
    "This can be achieved by considering $A \\Sigma_0 A^T$-orthonormal search directions, i.e. $\\inprod{s_i}{s_j}_{A \\Sigma_0 A^T} = \\delta_{ij}$. In this case, we have $(\\Lambda_m)_{i,j} = \\delta_{ij}$ and thus\n",
    "\\begin{align}\n",
    "    \\mu_m\n",
    "    & = \\mu_0 + \\Sigma_0 A^T S_m S_m^T r_0 \\\\\n",
    "    & = \\mu_0 + \\Sigma_0 A^T \\sum_{i = 1}^m s_i s_i^T r_0 \\\\\n",
    "    & = \\mu_0 + \\Sigma_0 A^T \\sum_{i = 1}^{m - 1} s_i s_i^T r_0 + \\Sigma_0 A^T s_m s_m^T r_0 \\\\\n",
    "    & = \\mu_0 + \\Sigma_0 A^T S_{m - 1} S_{m - 1}^T r_0 + \\Sigma_0 A^T s_m (s_m^T b - s_m^T A \\mu_0) \\\\\n",
    "    & = \\mu_{m - 1} + \\Sigma_0 A^T s_m (s_m^T b - s_m^T A \\mu_0 - \\underbrace{s_m^T A \\Sigma_0 A^T S_{m - 1}}_{= 0} S_{m - 1}^T r_0) \\\\\n",
    "    & = \\mu_{m - 1} + \\Sigma_0 A^T s_m s_m^T (b - A (\\mu_0 + \\Sigma_0 A^T S_{m - 1} S_{m - 1}^T r_0)) \\\\\n",
    "    & = \\mu_{m - 1} + \\Sigma_0 A^T s_m s_m^T \\underbrace{(b - A \\mu_{m - 1})}_{=: r_{m - 1}}\n",
    "\\end{align}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align}\n",
    "    \\Sigma_m\n",
    "    & = \\Sigma_0 - \\Sigma_0 A^T S_m S_m^T A \\Sigma_0 \\\\\n",
    "    & = \\Sigma_0 - \\Sigma_0 A^T \\sum_{i = 1}^m s_i s_i^T A \\Sigma_0 \\\\\n",
    "    & = \\Sigma_0 - \\Sigma_0 A^T \\sum_{i = 1}^{m - 1} s_i s_i^T A \\Sigma_0 - \\Sigma_0 A^T s_i s_i^T A \\Sigma_0 \\\\\n",
    "    & = \\Sigma_0 - \\Sigma_0 A^T S_{m - 1} S_{m - 1}^T A \\Sigma_0 - \\Sigma_0 A^T s_i (\\Sigma_0 A^T s_i)^T \\\\\n",
    "    & = \\Sigma_{m - 1} - \\Sigma_0 A^T s_i (\\Sigma_0 A^T s_i)^T.\n",
    "\\end{align}\n",
    "\n",
    "We can generate $A \\Sigma_0 A^T$-orthonormal search directions $s_m$ on-the-fly as in CG, i.e. $s_m = \\frac{\\tilde{s}_m}{\\norm{\\tilde{s}_m}_{A \\Sigma_0 A^T}}$, $\\tilde{s}_1 = r_0$ and\n",
    "\n",
    "\\begin{align}\n",
    "    \\tilde{s}_m = r_{m - 1} - \\inprod{s_{m - 1}}{r_{m - 1}}_{A \\Sigma_0 A^T} s_{m - 1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2d39b5-14b8-497d-8fdd-b50b15f3cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import probnum as pn\n",
    "import scipy.sparse\n",
    "\n",
    "import probnum_galerkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6095979-09ed-42f2-b901-9fde426b0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd5af8b-eed7-4879-870e-ea4e5957d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = (-1.0, 1.0)\n",
    "\n",
    "bvp = probnum_galerkin.problems.PoissonEquation(\n",
    "    domain=domain,\n",
    "    rhs=2.0,\n",
    "    boundary_condition=probnum_galerkin.problems.DirichletBoundaryCondition(\n",
    "        domain,\n",
    "        (0.0, 0.0),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee82b57-c38c-4154-9756-09674e567eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = probnum_galerkin.bases.ZeroBoundaryFiniteElementBasis(domain, num_elements=103)\n",
    "linsys = bvp.discretize(basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb122a2e-abe3-4200-b35d-77882aba73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayescg(A, b, x0=None, maxiter=None, atol=1e-5, rtol=1e-5, callback=None):\n",
    "    # Prior construction\n",
    "    x_dtype = np.result_type(A.dtype, b.dtype)\n",
    "    \n",
    "    if isinstance(x0, pn.randvars.Normal):\n",
    "        (x0, cov0) = (x0.mean, x0.cov)\n",
    "        \n",
    "        x0 = x0.astype(x_dtype, copy=True)\n",
    "        cov0 = cov0.astype(x_dtype, copy=True)\n",
    "    else:\n",
    "        if isinstance(x0, np.ndarray):\n",
    "            x0 = x0.astype(x_dtype, copy=True)\n",
    "        else:\n",
    "            assert x0 is None\n",
    "\n",
    "            x0 = np.zeros(A.shape[1], x_dtype)\n",
    "        \n",
    "        cov0 = pn.linops.aslinop(A).inv()\n",
    "        \n",
    "    # Stopping Criteria\n",
    "    if maxiter is None:\n",
    "        maxiter = 10 * x0.size\n",
    "        \n",
    "    res_norm_thresh = np.maximum(rtol * np.linalg.norm(b), atol)\n",
    "    \n",
    "    # Callback\n",
    "    if callback is None:\n",
    "        callback = lambda **kwargs: None\n",
    "    \n",
    "    # Initialization\n",
    "    x = x0\n",
    "    cov = cov0\n",
    "    nu = 0.0\n",
    "    \n",
    "    residual = b - A @ x\n",
    "    prev_residual = None\n",
    "    \n",
    "    s = residual\n",
    "    \n",
    "    # Check if initialization meets stopping criteria\n",
    "    stop = np.linalg.norm(residual, ord=2) < res_norm_thresh\n",
    "    \n",
    "    # Callback\n",
    "    callback(\n",
    "        iteration=0,\n",
    "        x=pn.randvars.Normal(mean=x0.copy(), cov=cov0),\n",
    "        residual=residual.copy(),\n",
    "        stop=stop,\n",
    "        action=None,\n",
    "    )\n",
    "    \n",
    "    # Iterate\n",
    "    if not stop:\n",
    "        for m in range(1, maxiter + 1):\n",
    "            # Update belief\n",
    "            E_sq = s.T @ A @ cov0 @ A.T @ s\n",
    "            alpha = residual.T @ residual / E_sq\n",
    "\n",
    "            x += alpha * (cov0 @ A.T @ s)\n",
    "            cov -= np.outer(cov0 @ A.T @ s, cov0 @ A.T @ s) / E_sq\n",
    "            nu += alpha\n",
    "\n",
    "            # Update residual\n",
    "            prev_residual = residual\n",
    "            residual = b - A @ x\n",
    "\n",
    "            # Check stopping criterion\n",
    "            stop = np.linalg.norm(residual, ord=2) < res_norm_thresh\n",
    "\n",
    "            # Callback\n",
    "            cov_scale = nu / m\n",
    "\n",
    "            callback(\n",
    "                iteration=m,\n",
    "                x=pn.randvars.Normal(mean=x.copy(), cov=cov_scale * cov),\n",
    "                cov_scale=cov_scale,\n",
    "                residual=residual,\n",
    "                stop=stop,\n",
    "                action=s,\n",
    "            )\n",
    "\n",
    "            # Apply stopping criterion\n",
    "            if stop:\n",
    "                break\n",
    "\n",
    "            # Update search direction\n",
    "            beta = (residual.T @ residual) / (prev_residual.T @ prev_residual)\n",
    "            s = residual + beta * s\n",
    "    \n",
    "    return pn.randvars.Normal(\n",
    "        mean=x,\n",
    "        cov=(nu / m) * cov,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ecdc0b-a9da-423e-a4fb-a3c32cc6415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probnum_galerkin.solvers import bayescg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e4bbd4-f367-47c3-8b89-61a294f239f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Union\n",
    "\n",
    "\n",
    "def problinsolve(\n",
    "    A: pn.linops.LinearOperatorLike,\n",
    "    b: np.ndarray,\n",
    "    prior_x: Optional[Union[pn.randvars.Normal, np.ndarray]] = None,\n",
    "    auto_cov_type: str = \"cg\",\n",
    "    max_num_steps: Optional[int] = None,\n",
    "    rtol: float = 1e-5,\n",
    "    atol: float = 1e-5,\n",
    "    callback: Callable[..., None] = None,\n",
    "):\n",
    "    A = pn.linops.aslinop(A)\n",
    "    \n",
    "    # Prior construction\n",
    "    if isinstance(prior_x, pn.randvars.Normal):\n",
    "        x0 = prior_x.mean.astype(np.result_type(A.dtype, b.dtype), copy=True)\n",
    "        cov0 = prior_x.cov.astype(x0.dtype, copy=True)\n",
    "    else:\n",
    "        if isinstance(prior_x, np.ndarray):\n",
    "            x0 = prior_x.astype(np.result_type(A.dtype, b.dtype), subok=True, copy=True)\n",
    "        else:\n",
    "            assert prior_x is None\n",
    "\n",
    "            x0 = np.zeros(A.shape[1], np.result_type(A.dtype, b.dtype))\n",
    "            \n",
    "        if auto_cov_type == \"id\":\n",
    "            cov0 = np.eye(x0.size, dtype=x0.dtype)\n",
    "        elif auto_cov_type == \"cg\":\n",
    "            cov0 = A.inv()\n",
    "        \n",
    "    # Stopping Criteria\n",
    "    if max_num_steps is None:\n",
    "        max_num_steps = 10 * x0.size\n",
    "        \n",
    "    res_norm_thresh = np.maximum(rtol * np.linalg.norm(b), atol)\n",
    "    \n",
    "    # Callback\n",
    "    if callback is None:\n",
    "        callback = lambda **kwargs: None\n",
    "    \n",
    "    # Initialization\n",
    "    step_idx = 0\n",
    "    \n",
    "    x = x0\n",
    "    cov = cov0\n",
    "    \n",
    "    residual = b - A @ x\n",
    "    residual_norm_sq = np.inner(residual, residual)\n",
    "    residual_norm = np.sqrt(residual_norm_sq)\n",
    "    \n",
    "    stop = (\n",
    "        step_idx >= max_num_steps\n",
    "        or residual_norm < res_norm_thresh\n",
    "    )\n",
    "    \n",
    "    callback(\n",
    "        step_idx=step_idx,\n",
    "        x=pn.randvars.Normal(mean=x.copy(), cov=cov),\n",
    "        residual=residual.copy(),\n",
    "        residual_norm_sq=residual_norm_sq,\n",
    "        residual_norm=residual_norm,\n",
    "        stop=stop,\n",
    "        action=None,\n",
    "        observation=None,\n",
    "        stepdir=None,\n",
    "        stepsize=None,\n",
    "    )\n",
    "    \n",
    "    action = residual\n",
    "    \n",
    "    # Iteration\n",
    "    prev_residual = None\n",
    "    prev_residual_norm_sq = None\n",
    "    \n",
    "    while not stop:\n",
    "        observation = np.inner(action, residual)\n",
    "        \n",
    "        matvec = A @ action\n",
    "        \n",
    "        # Update solution\n",
    "        stepdir = cov @ matvec\n",
    "        \n",
    "        gram = np.inner(matvec, stepdir)\n",
    "        # gram_pinv = 1.0 / gram if gram >= 12 ** -7 else 0.0\n",
    "        gram_pinv = 1.0 / gram\n",
    "        \n",
    "        stepsize = gram_pinv * observation\n",
    "        \n",
    "        x += stepsize * stepdir\n",
    "        cov -= np.outer(stepdir, stepdir) * gram_pinv\n",
    "        \n",
    "        # Update residual\n",
    "        prev_residual = residual\n",
    "        prev_residual_norm_sq = residual_norm_sq\n",
    "\n",
    "        residual = b - A @ x\n",
    "        residual_norm_sq = np.inner(residual, residual)\n",
    "        residual_norm = np.sqrt(residual_norm_sq)\n",
    "        \n",
    "        # Check stopping criteria\n",
    "        step_idx += 1\n",
    "        \n",
    "        stop = (\n",
    "            step_idx >= max_num_steps\n",
    "            or residual_norm < res_norm_thresh\n",
    "        )\n",
    "        \n",
    "        # Callback\n",
    "        callback(\n",
    "            step_idx=step_idx,\n",
    "            x=pn.randvars.Normal(mean=x.copy(), cov=cov),\n",
    "            residual=residual,\n",
    "            residual_norm=residual_norm,\n",
    "            stop=stop,\n",
    "            action=action,\n",
    "            observation=observation,\n",
    "            stepdir=stepdir,\n",
    "            stepsize=stepsize,\n",
    "        )\n",
    "\n",
    "        # Apply stopping criteria\n",
    "        if stop:\n",
    "            break\n",
    "        \n",
    "        # Update action\n",
    "        action = residual + (residual_norm_sq / prev_residual_norm_sq) * action\n",
    "    \n",
    "    return pn.randvars.Normal(\n",
    "        mean=x,\n",
    "        cov=cov,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4dbc5-11c7-42d4-bef1-f49b9961d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.random.randn(10, 10)\n",
    "A = M @ M.T + np.eye(10)\n",
    "b = np.random.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab067d-e68d-460c-92e0-b62049a4cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de1068-3768-4c1c-8882-a484d953f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol = bayescg(pn.problems.LinearSystem(A, b))\n",
    "sol = bayescg(A, b)\n",
    "sol.mean, sol.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3445988-23d5-4e6e-9507-bd49afd119c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_fem_coords = bayescg(linsys.A, linsys.b, maxiter=40, rtol=0, atol=0)\n",
    "u_fem = basis.coords2fn(u_fem_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3200bc8-6ef4-4eec-9d41-6b38843d5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_plot = np.linspace(*domain, 200)\n",
    "\n",
    "mean = u_fem.mean(xs_plot)\n",
    "std = u_fem.std(xs_plot[:, None])\n",
    "\n",
    "plt.plot(xs_plot, bvp.solution(xs_plot))\n",
    "plt.plot(xs_plot, mean, c=\"C1\")\n",
    "plt.fill_between(\n",
    "    xs_plot,\n",
    "    mean - 1.96 * std,\n",
    "    mean + 1.96 * std,\n",
    "    alpha=0.1,\n",
    "    color=\"C1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fafa7b-f363-44e2-8fbb-1fd8a375209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "def animate_poisson_1d_bayescg(basis, linsys=None, **bayescg_kwargs):\n",
    "    n = len(basis)\n",
    "    \n",
    "    if linsys is None:\n",
    "        linsys = bvp.discretize(basis)\n",
    "    \n",
    "    # Run the algorithm and log step statistics\n",
    "    step_xs = []\n",
    "    step_residual_norms = []\n",
    "    step_residual_A_norms = []\n",
    "\n",
    "    def _callback(x: pn.randvars.Normal, residual: np.ndarray, **kwargs):\n",
    "        step_xs.append(x)\n",
    "        step_residual_norms.append(np.linalg.norm(residual, ord=2))\n",
    "        step_residual_A_norms.append(np.sqrt(np.inner(residual, linsys.A @ residual)))\n",
    "\n",
    "    bayescg(\n",
    "        linsys.A,\n",
    "        linsys.b,\n",
    "        callback=_callback,\n",
    "        **bayescg_kwargs\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(22, 6))\n",
    "    plt.close()\n",
    "    \n",
    "    xs_plot = np.linspace(*domain, 200)\n",
    "\n",
    "    def animate(step_idx):\n",
    "        ax[0].cla()\n",
    "        ax[1].cla()\n",
    "        ax[2].cla()\n",
    "\n",
    "        u = basis.coords2fn(coords=step_xs[step_idx])\n",
    "        \n",
    "        u_mean_plot = u.mean(xs_plot)\n",
    "        u_std_plot = u.std(xs_plot[:, None])\n",
    "\n",
    "        fig.suptitle(f\"1D Poisson - FEM (N = {n}) - BayesCG - Iteration {step_idx:03d}\")\n",
    "\n",
    "        ax[0].set_title(\"Solution\")\n",
    "        #ax[0].set_ylim(-1.3, np.max(mean + 2 * std) + 0.1)\n",
    "        ax[0].plot(xs_plot, bvp.solution(xs_plot), label=\"Exact Solution\")\n",
    "        ax[0].plot(xs_plot, u_mean_plot, c=\"C1\", label=\"FEM Solution\")\n",
    "        ax[0].fill_between(\n",
    "            xs_plot,\n",
    "            u_mean_plot - 2 * u_std_plot,\n",
    "            u_mean_plot + 2 * u_std_plot,\n",
    "            color=\"C1\",\n",
    "            alpha=0.2,\n",
    "        )\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].set_title(\"Residual Norm\")\n",
    "        ax[1].plot(step_residual_norms[:step_idx + 1], \"C0\", label=\"residual norm\")\n",
    "        # ax[1].legend(loc=\"upper right\")\n",
    "        ax[1].set_xlabel(\"Iterations\")\n",
    "        \n",
    "        ax[2].set_title(\"Residual A-norm\")\n",
    "        ax[2].plot(step_residual_A_norms[:step_idx + 1], \"C0\", label=\"residual norm\")\n",
    "        ax[2].set_xlabel(\"Iterations\")\n",
    "\n",
    "    return animation.FuncAnimation(\n",
    "        fig,\n",
    "        func=animate,\n",
    "        frames=len(step_xs),\n",
    "        interval=200,\n",
    "        repeat_delay=4000,\n",
    "        blit=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b0d4d-ee10-4e1d-bb06-4cd645040798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "anim = animate_poisson_1d_bayescg(\n",
    "    basis,\n",
    "    maxiter=len(basis),\n",
    ")\n",
    "\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19dc08-bb49-48ce-a84b-a172b5ebdf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save(\"../results/fem_probsolve.gif\", animation.PillowWriter(fps=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5469580-51b0-47e7-abaa-ebde2e1b74ea",
   "metadata": {},
   "source": [
    "## Conditioning the Prior on Observations of the Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba9daf-e77b-4db6-9998-49a6cabe028f",
   "metadata": {},
   "source": [
    "u_prior_cond_measIf we have (noisy) measurements of the solution of the PDE, we can use the information to speed up inference.\n",
    "\n",
    "Let $(v_i)_{i = 1}^n$ be the chosen basis.\n",
    "In our formulation, we posit a multivariate Gaussian prior over the coefficients $\\vec{a} \\in \\mathbb{R}^n$ of the discretized solution $\\hat{u} = \\sum_{i = 1}^n a_i v_i$ to the PDE, i.e. $\\vec{a} \\sim \\mathcal{N}(\\mu_0, \\Sigma_0)$.\n",
    "We can relate the discretized solution $\\hat{u}$ to the coefficients by a linear operator $$(\\mathcal{L}_u \\vec{a})(x) = \\sum_{i = 1}^n a_i v_i(x).$$\n",
    "Moreover, the solution can be evaluated at several locations $x_1, \\dotsc, x_m \\in \\Omega$ by another linear operator $$(\\mathcal{L}_\\delta u)_j = \\int_\\Omega \\delta(\\chi - x_j) u(\\chi) d \\chi = u(x_j).$$\n",
    "All in all, we obtain the following linear operator which maps $\\vec{a}$ to a vector of measurements at $x_1, \\dotsc, x_m \\in \\Omega$: $$(L_y \\vec{a})_j = (\\mathcal{L}_\\delta \\mathcal{L}_u \\vec{a})_j = \\int_\\Omega \\delta(\\chi - x_j) (\\mathcal{L}_u \\vec{a})(\\chi) d \\chi = \\sum_{i = 1}^n a_i \\int_\\Omega \\delta(\\chi - x_j) v_i(\\chi) d\\chi = \\sum_{i = 1}^n a_i v_i(x_j)$$\n",
    "If we now assume additive Gaussian measurement noise on independent observations $y_1, \\dotsc, y_m$ of the solution at locations $x_1, \\dotsc, x_m \\in \\Omega$, we obtain the following measurement likelihood:\n",
    "$$p(y_1, \\dots, y_m \\mid u(x_1), \\dotsc, u(x_m)) = \\mathcal{N}(\\vec{y} \\mid \\begin{pmatrix} u(x_1), \\dotsc, u(x_m) \\end{pmatrix}^T, \\Lambda),$$\n",
    "or, equivalently,\n",
    "$$p(y_1, \\dots, y_m \\mid \\vec{a}) = \\mathcal{N}(\\vec{y} \\mid L_\\vec{y} \\vec{a}, \\Lambda).$$\n",
    "Since the model is linear-Gaussian, we can compute the posterior in closed form.\n",
    "Note that this is exactly the supervised regression setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac7008-dcd5-49c5-a659-d6fe189f24ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_measurements = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d77817-698e-4776-ad01-ed330d6bfcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the solution at equidistant interior points\n",
    "meas_xs = np.linspace(*domain, num_measurements + 2)[1:-1]\n",
    "true_ys = bvp.solution(meas_xs)\n",
    "\n",
    "# Add measurement noise\n",
    "measurement_noise = pn.randvars.Normal(\n",
    "    mean=np.zeros(num_measurements, dtype=np.double),\n",
    "    cov=pn.linops.Scaling((1e-2) ** 2, shape=num_measurements, dtype=np.double),\n",
    ")\n",
    "\n",
    "meas_ys = true_ys + measurement_noise.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42404d9-005e-4bba-8cc8-45e65fb13edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_ys - true_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3456196-3878-4ca6-a3d2-ac7c6bf031e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the prior\n",
    "prior = pn.randvars.Normal(\n",
    "    mean=np.zeros(len(basis), dtype=np.double),\n",
    "    cov=2.0 * linsys.A.inv(),\n",
    ")\n",
    "\n",
    "np.linalg.cond(prior.dense_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efec94-9e87-49a2-8814-27a219fd776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the observation operator\n",
    "L_yu = basis.observation_operator(meas_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71014f4b-6f46-4d94-92df-e8072c608fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the noise model\n",
    "noise_model = pn.randvars.Normal(\n",
    "    mean=np.zeros(num_measurements, dtype=np.double),\n",
    "    cov=measurement_noise.cov,\n",
    "    # cov=1e2 * measurement_noise.cov,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03173319-d1fe-42c1-be56-ac8422ebc36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition the prior on the measurements\n",
    "prior_cond_meas = probnum_galerkin.inference.linear_gaussian_model(\n",
    "    prior=prior,\n",
    "    A=L_yu,\n",
    "    measurement_noise=noise_model,\n",
    "    measurements=meas_ys,\n",
    ")\n",
    "\n",
    "np.linalg.cond(prior_cond_meas.dense_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0382486-526c-42bb-ad3d-5a2b23343900",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_plot = np.linspace(*domain, 200)\n",
    "\n",
    "u_prior_cond_meas = basis.coords2fn(prior_cond_meas)(xs_plot[:, None])\n",
    "\n",
    "plt.plot(xs_plot, u_prior_cond_meas.mean)\n",
    "plt.fill_between(\n",
    "    xs_plot,\n",
    "    np.squeeze(u_prior_cond_meas.mean - 1.96 * u_prior_cond_meas.std),\n",
    "    np.squeeze(u_prior_cond_meas.mean + 1.96 * u_prior_cond_meas.std),\n",
    "    alpha=0.1\n",
    ")\n",
    "plt.scatter(meas_xs, meas_ys, marker=\"+\")\n",
    "# plt.errorbar(meas_xs, meas_ys, yerr=2 * measurement_noise.std, marker=\"+\", linestyle=\"\", capsize=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c946a5-7f75-459c-a386-c4211a2e7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "anim = animate_poisson_1d_bayescg(\n",
    "    basis,\n",
    "    linsys=linsys,\n",
    "    x0=prior_cond_meas,\n",
    "    maxiter=len(basis),\n",
    "    #atol=0,\n",
    "    #rtol=0,\n",
    "    #reorthogonalize=True,\n",
    ")\n",
    "\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4fa8da-e4fa-414d-b917-e3c60dae84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save(\"../results/fem_probsolve_data.gif\", animation.PillowWriter(fps=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c05a1-dd27-49de-9dcf-157a99cce558",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(np.sort(linsys.A.eigvals()))\n",
    "plt.semilogy(np.sort((linsys.A @ prior_cond_meas.cov @ linsys.A).eigvals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d45564-5abc-4eff-865b-fe509656a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = np.sort((linsys.A @ prior_cond_meas.cov @ linsys.A).eigvals())\n",
    "spec.min(), spec.max(), spec.max() / spec.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19a93f-24df-4ac6-8477-621fed1c3785",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = np.sort(linsys.A.eigvals())\n",
    "spec.min(), spec.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934c6a4-71ff-4fe5-bf8b-13995e53e04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:probnum]",
   "language": "python",
   "name": "conda-env-probnum-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
